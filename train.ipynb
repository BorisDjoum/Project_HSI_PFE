{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321599b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spectral as spy\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from functools import partial # Nécessaire pour fixer les arguments\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "\n",
    "# *** IMPORT CRUCIAL ***\n",
    "from data_processor import process_single_image_and_save, compute_hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14d7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_metadata_csv(base_dir, output_csv_file='hyperspectral_metadata.csv'):\n",
    "    \"\"\"\n",
    "    Parcourt les dossiers de catégories (G1-G4), extrait les métadonnées de chaque image \n",
    "    et les sauvegarde dans un fichier CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    categories = ['G1', 'G2', 'G3', 'G4']\n",
    "    data_dirs = [os.path.join(base_dir, cat) for cat in categories]\n",
    "    \n",
    "    metadata_list = []\n",
    "    \n",
    "    # En-têtes du fichier CSV\n",
    "    fieldnames = ['Nom_Fichier_HDR', 'Classe', 'Lignes', 'Colonnes', 'Bandes']\n",
    "    \n",
    "    print(f\"Extraction des métadonnées des dossiers : {categories}...\")\n",
    "\n",
    "    # Boucle sur les dossiers de catégories\n",
    "    for category_path in data_dirs:\n",
    "        class_name = os.path.basename(category_path) # Ex: 'G1'\n",
    "        \n",
    "        # Chercher tous les fichiers .hdr qui ne sont pas des références Dark/White\n",
    "        image_files_hdr = glob(os.path.join(category_path, '**', '*.hdr'), recursive=True)\n",
    "        image_files_hdr = [f for f in image_files_hdr if 'Dark' not in f and 'White' not in f and 'Calib' not in f and 'white' not in f]\n",
    "\n",
    "        if not image_files_hdr:\n",
    "            print(f\"Avertissement : Aucune image de mesure trouvée dans {class_name}.\")\n",
    "            continue\n",
    "\n",
    "        for hdr_file in image_files_hdr:\n",
    "            try:\n",
    "                # Utiliser spy.open_image (ou spy.envi.open) sans charger le .bin\n",
    "                # L'objet Image généré par spy contient les métadonnées.\n",
    "                img_metadata = spy.envi.open(hdr_file, hdr_file.replace('.hdr', '.bin')) \n",
    "                \n",
    "                # Récupération des informations\n",
    "                file_name_only = os.path.basename(hdr_file)\n",
    "                # 3. CORRECTION : Accéder aux dimensions par la propriété .shape\n",
    "                # La forme est (Lignes, Colonnes, Bandes)\n",
    "                lines, samples, bands = img_metadata.shape\n",
    "                \n",
    "                metadata_list.append({\n",
    "                    'Nom_Fichier_HDR': file_name_only,\n",
    "                    'Classe': class_name,\n",
    "                    'Lignes': lines,\n",
    "                    'Colonnes': samples,\n",
    "                    'Bandes': bands\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Capture les erreurs si un fichier .hdr est mal formé ou si le .bin est introuvable (mais les metadata sont souvent lues quand même)\n",
    "                print(f\"Erreur de lecture des métadonnées pour {os.path.basename(hdr_file)}: {e}\")\n",
    "\n",
    "    # --- Écriture du fichier CSV ---\n",
    "    try:\n",
    "        with open(output_csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(metadata_list)\n",
    "            \n",
    "        print(f\"\\nSUCCESS: Le fichier CSV de métadonnées a été créé : {output_csv_file}\")\n",
    "        print(f\"Total de {len(metadata_list)} images documentées.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR lors de l'écriture du fichier CSV : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20e968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BASE_DIR doit pointer vers le répertoire parent contenant G1, G2, G3, G4.\n",
    "# BASE_DIR = '/Volumes/Elements/Framatome' \n",
    "\n",
    "# # L'exécution crée le fichier hyperspectral_metadata.csv\n",
    "# create_metadata_csv(BASE_DIR, output_csv_file='hyperspectral_dataset_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6997ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_class_from_filename(file_name):\n",
    "    for cat in ['G1', 'G2', 'G3', 'G4']:\n",
    "        if cat in file_name:\n",
    "            return cat\n",
    "    return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b11be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOG_FILE = 'processed_hdrs_log.txt'\n",
    "DATASET_REFLEC_DIR = 'dataset_reflec_test'\n",
    "\n",
    "# --- NOUVELLE VERSION DE create_dataset AVEC PARALLÉLISATION ---\n",
    "def create_dataset_parallel(base_dir, max_workers=None): # max_workers par défaut aux cœurs du CPU\n",
    "    # ... (le début du code reste le même, y compris la recherche des références Dark/White) ...\n",
    "    \n",
    "    L_min = 708\n",
    "    # 1. PRÉPARATION ET CRÉATION DU DOSSIER CIBLE\n",
    "    os.makedirs(DATASET_REFLEC_DIR, exist_ok=True) # Crée le dossier s'il n'existe pas\n",
    "\n",
    "    # Définir le mapping des catégories (labels numériques)\n",
    "    categories = ['G1', 'G2', 'G3', 'G4']\n",
    "    label_map = {cat: i for i, cat in enumerate(categories)}\n",
    "    \n",
    "    # Dossiers contenant les images hyperspectrales\n",
    "    data_dirs = [os.path.join(base_dir, cat) for cat in categories]\n",
    "    # Liste pour stocker les tâches à exécuter\n",
    "    tasks = [] \n",
    "    \n",
    "    # Boucle sur les catégories pour générer les tâches (sans les exécuter)\n",
    "    # for category_path in data_dirs:\n",
    "    #     # 1. Résoudre le chemin réel du fichier DARK/WHITE (références spécifiques à la catégorie)\n",
    "    #     # ... (glob pour dark_hdr et white_hdr, puis vérification de l'existence)\n",
    "    #     # 1. Résoudre le chemin réel du fichier DARK\n",
    "    #     # chaque catégorie a son propre fichier de référence Dark/White CalibFin ou CalibEnd\n",
    "\n",
    "    #     # Motif général pour les fichiers contenant 'Dark' et l'extension .hdr\n",
    "    #     dark_pattern = os.path.join(category_path, '**', '*Dark*.hdr')\n",
    "    #     # Motif général pour les fichiers contenant 'White' et l'extension .hdr\n",
    "    #     white_pattern = os.path.join(category_path, '**', '*White*.hdr')\n",
    "\n",
    "    #     # --- 2. Recherche et Filtrage ---\n",
    "    \n",
    "    #     # On cherche tous les Dark/White\n",
    "    #     dark_candidates = glob(dark_pattern, recursive=True)\n",
    "    #     white_candidates = glob(white_pattern, recursive=True)\n",
    "\n",
    "    #     # Filtrage : On ne retient que ceux qui contiennent le mot 'Calib' pour s'assurer que ce sont des références.\n",
    "    #     # On s'assure aussi de ne pas avoir de duplication.\n",
    "    #     dark_ref_list = [f for f in dark_candidates if 'Calib' in f or 'calib' in f]\n",
    "    #     white_ref_list = [f for f in white_candidates if 'Calib' in f or 'calib' in f]\n",
    "        \n",
    "    #     # Enlève les doublons si glob trouve des chemins multiples pour le même fichier (peu probable, mais sécurisant)\n",
    "    #     dark_ref_list = list(set(dark_ref_list))\n",
    "    #     white_ref_list = list(set(white_ref_list))\n",
    "\n",
    "    #     # Vérifier et extraire le chemin\n",
    "    #     if not dark_ref_list or not white_ref_list:\n",
    "    #         print(f\"Avertissement : Références CalibFin/CalibEnd Dark/White manquantes dans {category_path}. Catégorie ignorée.\")\n",
    "    #         continue\n",
    "        \n",
    "    #     dark_hdr = dark_ref_list[0]\n",
    "    #     white_hdr = white_ref_list[0]\n",
    "    #     label = label_map.get(os.path.basename(category_path), -1)\n",
    "\n",
    "    #     # 2. Chercher les images de mesure\n",
    "    #     image_files_hdr = glob(os.path.join(category_path, '**', '*.hdr'), recursive=True)\n",
    "    #     image_files_hdr = [f for f in image_files_hdr if 'Dark' not in f and 'White' not in f and 'white' not in f and 'Calib' not in f and 'calib' not in f]\n",
    "        \n",
    "    #     # 3. Créer une tâche pour chaque image de mesure\n",
    "    #     for hdr_file in image_files_hdr:\n",
    "    #         tasks.append({\n",
    "    #             'hdr': hdr_file, \n",
    "    #             'dark': dark_hdr, \n",
    "    #             'white': white_hdr, \n",
    "    #             'label': label\n",
    "    #         })\n",
    "\n",
    "    # --- Recherche des Références (Dark/White) - Logique de recherche robuste ---\n",
    "    dark_candidates = glob(os.path.join(base_dir, '**', '*Dark*.hdr'), recursive=True)\n",
    "    white_candidates = glob(os.path.join(base_dir, '**', '*White*.hdr'), recursive=True)\n",
    "\n",
    "    dark_ref_list = [f for f in dark_candidates if 'Calib' in f or 'calib' in f]\n",
    "    white_ref_list = [f for f in white_candidates if 'Calib' in f or 'calib' in f]\n",
    "    \n",
    "    dark_ref_list = list(set(dark_ref_list))\n",
    "    white_ref_list = list(set(white_ref_list))\n",
    "\n",
    "    if not dark_ref_list or not white_ref_list:\n",
    "        print(f\"Avertissement : Références Dark/White (Calib) manquantes dans {base_dir}. Catégorie ignorée.\")\n",
    "        \n",
    "\n",
    "    dark_hdr = dark_ref_list[0]\n",
    "    white_hdr = white_ref_list[0]\n",
    "\n",
    "    image_files_hdr = glob(os.path.join(base_dir, '**', '*.hdr'), recursive=True)\n",
    "    image_files_hdr = [f for f in image_files_hdr if 'Dark' not in f and 'White' not in f and 'Calib' not in f and 'calib' not in f and 'white' not in f]\n",
    "\n",
    "    for hdr_file in image_files_hdr:\n",
    "        class_name = extract_class_from_filename(hdr_file)\n",
    "        label = label_map.get(class_name, -1)\n",
    "        tasks.append({\n",
    "            'hdr': hdr_file, \n",
    "            'dark': dark_hdr, \n",
    "            'white': white_hdr, \n",
    "            'label': label\n",
    "        }) \n",
    "\n",
    "    # --- GESTION DE LA REPRISE (LOG des fichiers traités) ---\n",
    "    processed_hdrs = set()\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        with open(LOG_FILE, 'r') as f:\n",
    "            processed_hdrs = set(f.read().splitlines())\n",
    "    \n",
    "    # Filtrer les tâches pour ne garder que les fichiers non traités\n",
    "    tasks_to_process = [t for t in tasks if t['hdr'] not in processed_hdrs]\n",
    "    \n",
    "    print(f\"Total de fichiers à traiter (restants) : {len(tasks_to_process)} / {len(tasks)}.\")\n",
    "\n",
    "    # --- EXÉCUTION PARALLÈLE ET SAUVEGARDE INDIVIDUELLE ---\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Soumettre toutes les tâches restantes. Le résultat attendu est le cube de réflectance.\n",
    "        futures = {executor.submit(process_single_image_and_save, \n",
    "                                # Arguments existants\n",
    "                                t['hdr'], t['dark'], t['white'], t['label'], \n",
    "                                # NOUVEL ARGUMENT\n",
    "                                L_min): t['hdr'] \n",
    "               for t in tasks_to_process}\n",
    "        \n",
    "        # Boucle sur les résultats COMPLÉTÉS (as_completed)\n",
    "        for future in tqdm(as_completed(futures), total=len(tasks_to_process), desc=\"Calibration et Sauvegarde NPY\"):\n",
    "            \n",
    "            hdr_path = futures[future]\n",
    "            \n",
    "            try:\n",
    "                # La fonction process_single_image_and_save retourne None ou un booléen de succès\n",
    "                future.result() \n",
    "                \n",
    "                # Ajouter le fichier au log uniquement en cas de succès\n",
    "                with open(LOG_FILE, 'a') as f:\n",
    "                    f.write(f\"{hdr_path}\\n\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                 print(f\"\\n[ERREUR FATALE WORKER] sur {hdr_path}. Le processus a planté ou la sauvegarde a échoué: {e}\")\n",
    "                 # Le fichier n'est pas ajouté au log, il sera retraité à la prochaine exécution.\n",
    "                 continue\n",
    "\n",
    "    print(\"\\nFIN DE L'EXTRACTION. Tous les cubes de réflectance sont sauvegardés au format NPY.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fde959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CHARGER LE DATASET ---\n",
    "# Code à exécuter dans votre environnement principal\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Le reste de votre code de chargement ici\n",
    "#     BASE_DIR = '/Volumes/Elements/Framatome/Echantillons cibles' # Assurez-vous que ceci est défini!\n",
    "    \n",
    "#     # L'appel à la fonction est maintenant protégé\n",
    "#     create_dataset_parallel(BASE_DIR, max_workers=7) # Vous pouvez ajuster max_workers selon vos besoins\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a69296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes globales nécessaires à l'ensemble du script\n",
    "L_min = 708      # Nombre de lignes minimum (pour le redimensionnement spatial)\n",
    "BAND_START = 30  # Indice de bande pour 410 nm\n",
    "BAND_END = 465   # Indice de bande pour couper l'extrême fin (avant 1010 nm)\n",
    "DATASET_HIST_DIR = 'dataset_hist2'\n",
    "LOG_FILE = 'ghost_hist_processed_log.txt' # Nouveau log pour cette étape\n",
    "CHECKPOINT_FILE = 'ghost_hist_checkpoint.npz' # Nouveau checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6140d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_ghost_dataset(base_dir, max_workers=None): \n",
    "    \n",
    "    # 1. PRÉPARATION INITIALE DES TÂCHES\n",
    "    categories = ['G1', 'G2', 'G3', 'G4']\n",
    "    label_map = {cat: i for i, cat in enumerate(categories)}\n",
    "    # data_dirs = [os.path.join(base_dir, cat) for cat in categories]\n",
    "    tasks = [] \n",
    "    \n",
    "    # for category_path in data_dirs:\n",
    "    #     # --- Recherche des Références (Dark/White) - Logique de recherche robuste ---\n",
    "    #     dark_candidates = glob(os.path.join(category_path, '**', '*Dark*.hdr'), recursive=True)\n",
    "    #     white_candidates = glob(os.path.join(category_path, '**', '*White*.hdr'), recursive=True)\n",
    "\n",
    "    #     dark_ref_list = [f for f in dark_candidates if 'Calib' in f or 'calib' in f]\n",
    "    #     white_ref_list = [f for f in white_candidates if 'Calib' in f or 'calib' in f]\n",
    "        \n",
    "    #     dark_ref_list = list(set(dark_ref_list))\n",
    "    #     white_ref_list = list(set(white_ref_list))\n",
    "\n",
    "    #     if not dark_ref_list or not white_ref_list:\n",
    "    #         print(f\"Avertissement : Références Dark/White (Calib) manquantes dans {category_path}. Catégorie ignorée.\")\n",
    "    #         continue\n",
    "          \n",
    "    #     label = label_map.get(os.path.basename(category_path), -1)\n",
    "\n",
    "    #     # 2. Chercher les images de mesure\n",
    "    #     image_files_hdr = glob(os.path.join(category_path, '**', '*.hdr'), recursive=True)\n",
    "    #     image_files_hdr = [f for f in image_files_hdr if 'Dark' not in f and 'White' not in f and 'Calib' not in f and 'calib' not in f and 'white' not in f]\n",
    "        \n",
    "    #     # 3. Créer une tâche pour chaque image de mesure\n",
    "    #     for hdr_file in image_files_hdr:\n",
    "    #         tasks.append({\n",
    "    #             'hdr': hdr_file, \n",
    "    #             'label': label\n",
    "    #         })\n",
    "\n",
    "    # --- Recherche des Références (Dark/White) - Logique de recherche robuste ---\n",
    "    # dark_candidates = glob(os.path.join(base_dir, '**', '*Dark*.hdr'), recursive=True)\n",
    "    # white_candidates = glob(os.path.join(base_dir, '**', '*White*.hdr'), recursive=True)\n",
    "\n",
    "    # dark_ref_list = [f for f in dark_candidates if 'Calib' in f or 'calib' in f]\n",
    "    # white_ref_list = [f for f in white_candidates if 'Calib' in f or 'calib' in f]\n",
    "    \n",
    "    # dark_ref_list = list(set(dark_ref_list))\n",
    "    # white_ref_list = list(set(white_ref_list))\n",
    "\n",
    "    # if not dark_ref_list or not white_ref_list:\n",
    "    #     print(f\"Avertissement : Références Dark/White (Calib) manquantes dans {base_dir}. Catégorie ignorée.\")\n",
    "        \n",
    "\n",
    "    image_files_hdr = glob(os.path.join(base_dir, '**', '*.npy'), recursive=True)\n",
    "    # image_files_hdr = [f for f in image_files_hdr if 'Dark' not in f and 'White' not in f and 'Calib' not in f and 'calib' not in f and 'white' not in f]\n",
    "\n",
    "    for npy_file in image_files_hdr:\n",
    "        class_name = extract_class_from_filename(npy_file)\n",
    "        label = label_map.get(class_name, -1)\n",
    "        tasks.append({\n",
    "            'npy': npy_file, \n",
    "            'label': label\n",
    "        })  \n",
    "    \n",
    "\n",
    "    # 1. PRÉPARATION ET CRÉATION DU DOSSIER CIBLE\n",
    "    os.makedirs(DATASET_HIST_DIR, exist_ok=True)\n",
    "    \n",
    "    # 2. GESTION DE LA REPRISE (LOG des fichiers traités)\n",
    "    processed_hdrs = set()\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        with open(LOG_FILE, 'r') as f:\n",
    "            processed_hdrs = set(f.read().splitlines())\n",
    "    \n",
    "    # Filtrer les tâches pour ne garder que les fichiers non traités\n",
    "    tasks_to_process = [t for t in tasks if t['npy'] not in processed_hdrs]\n",
    "\n",
    "    # --- EXÉCUTION PARALLÈLE ET SAUVEGARDE INDIVIDUELLE ---\n",
    "    print(f\"Démarrage de l'extraction GHOST en parallèle sur {len(tasks_to_process)} fichiers...\")\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        \n",
    "        futures = {executor.submit(\n",
    "            compute_hist_features, \n",
    "            t['npy'], t['label']): t['npy'] for t in tasks_to_process}\n",
    "        \n",
    "        # Boucle sur les résultats COMPLÉTÉS\n",
    "        for future in tqdm(as_completed(futures), total=len(tasks_to_process), desc=\"Extraction GHOST et Sauvegarde\"):\n",
    "            \n",
    "            npy_path = futures[future]\n",
    "            \n",
    "            try:\n",
    "                # Le résultat est un booléen (True pour succès)\n",
    "                future.result() \n",
    "                \n",
    "                # Ajouter le fichier au log uniquement en cas de succès\n",
    "                with open(LOG_FILE, 'a') as f:\n",
    "                    f.write(f\"{npy_path}\\n\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                 print(f\"\\n[ERREUR FATALE WORKER] sur {npy_path}. Le processus a planté ou la sauvegarde a échoué: {e}\")\n",
    "                 continue\n",
    "\n",
    "    print(\"\\nFIN DE L'EXTRACTION GHOST. Tous les histogrammes sont sauvegardés individuellement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a079cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de l'extraction GHOST en parallèle sur 42 fichiers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:   0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0045459177\n",
      "9.821078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:   2%|▏         | 1/42 [32:21<22:06:22, 1941.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021350868\n",
      "8.82599\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0022824162\n",
      "1.3443063\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.002006473\n",
      "1.1204816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:   7%|▋         | 3/42 [39:02<6:08:39, 567.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0019607877\n",
      "3.663462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  10%|▉         | 4/42 [39:26<3:43:18, 352.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021816508\n",
      "9.76458\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021557184\n",
      "1.361698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  14%|█▍        | 6/42 [40:46<1:41:47, 169.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.002199829\n",
      "1.5664397\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0020604532\n",
      "0.7307255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  17%|█▋        | 7/42 [41:58<1:20:19, 137.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021586164\n",
      "1.4466221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  19%|█▉        | 8/42 [42:45<1:01:35, 108.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0020987915\n",
      "0.41717154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  21%|██▏       | 9/42 [43:33<49:21, 89.74s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021545019\n",
      "2.2619135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  29%|██▊       | 12/42 [44:51<22:52, 45.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0043770103\n",
      "2.1480596\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0042127366\n",
      "17.735151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  31%|███       | 13/42 [52:34<1:23:16, 172.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0043609454\n",
      "6.7012477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  33%|███▎      | 14/42 [53:21<1:02:46, 134.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.002176766\n",
      "3.9548194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  36%|███▌      | 15/42 [54:05<48:13, 107.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0020621964\n",
      "12.340989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  38%|███▊      | 16/42 [54:50<38:17, 88.36s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0037903846\n",
      "1.7758847\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0040387977\n",
      "3.520738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  40%|████      | 17/42 [56:04<35:02, 84.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0038887495\n",
      "1.4738251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  43%|████▎     | 18/42 [56:52<29:14, 73.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0043572946\n",
      "18.953337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  45%|████▌     | 19/42 [57:35<24:35, 64.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.003969219\n",
      "3.1229744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  52%|█████▏    | 22/42 [58:48<12:27, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021340917\n",
      "0.9535118\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0041544233\n",
      "6.799915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  55%|█████▍    | 23/42 [1:02:29<29:18, 92.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0020865288\n",
      "1.015811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  57%|█████▋    | 24/42 [1:03:19<23:52, 79.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0020297437\n",
      "0.41612822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  60%|█████▉    | 25/42 [1:04:05<19:43, 69.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021650272\n",
      "11.469391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  62%|██████▏   | 26/42 [1:04:51<16:38, 62.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021697986\n",
      "2.2032123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  64%|██████▍   | 27/42 [1:05:38<14:27, 57.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0036033504\n",
      "12.860927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  67%|██████▋   | 28/42 [1:06:23<12:36, 54.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.00207437\n",
      "1.3456863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  71%|███████▏  | 30/42 [1:07:28<08:22, 41.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.003870546\n",
      "3.0878158\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.004206337\n",
      "2.6045809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  74%|███████▍  | 31/42 [1:08:35<09:01, 49.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.004266511\n",
      "5.2094626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  76%|███████▌  | 32/42 [1:09:20<08:01, 48.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0023205082\n",
      "2.8241193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  79%|███████▊  | 33/42 [1:10:04<07:02, 46.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0039488287\n",
      "29.682009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  81%|████████  | 34/42 [1:10:45<06:01, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0045064087\n",
      "13.778029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  86%|████████▌ | 36/42 [1:11:47<03:40, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0039969003\n",
      "2.3635175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  88%|████████▊ | 37/42 [1:13:13<04:18, 51.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0037955882\n",
      "10.585228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde:  90%|█████████ | 38/42 [1:13:33<02:47, 41.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0020281973\n",
      "1.2270564\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0021886837\n",
      "2.9969616\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0019319281\n",
      "1.8136226\n",
      "(708, 1000, 435)\n",
      "(708, 1000, 435)\n",
      "(708, 1000)\n",
      "(708, 1000)\n",
      "0.0019878505\n",
      "0.6545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction GHOST et Sauvegarde: 100%|██████████| 42/42 [1:16:15<00:00, 108.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIN DE L'EXTRACTION GHOST. Tous les histogrammes sont sauvegardés individuellement.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Le reste de votre code de chargement ici\n",
    "    BASE_DIR = 'dataset_reflec' # Assurez-vous que ceci est défini!\n",
    "    \n",
    "    # L'appel à la fonction est maintenant protégé\n",
    "    create_ghost_dataset(BASE_DIR, max_workers=6) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65af6f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b077b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser mathplotlib pour visualiser quelques histogrammes extraits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def visualiser_histogrammes_echantillons(hist_dir, nb_echantillons=5):\n",
    "    \"\"\"\n",
    "    Visualise des histogrammes aléatoires à partir d'un répertoire\n",
    "    \n",
    "    Paramètres:\n",
    "        hist_dir: Chemin du répertoire contenant les histogrammes\n",
    "        nb_echantillons: Nombre d'échantillons à visualiser\n",
    "    \"\"\"\n",
    "    # Obtenir tous les fichiers .npy dans le répertoire\n",
    "    fichiers_hist = glob(os.path.join(hist_dir, '*.npy'))\n",
    "    \n",
    "    if len(fichiers_hist) == 0:\n",
    "        print(\"Aucun fichier d'histogramme trouvé.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Trouvé {len(fichiers_hist)} fichiers d'histogrammes\")\n",
    "    \n",
    "    # Sélection aléatoire d'échantillons\n",
    "    echantillons_fichiers = np.random.choice(\n",
    "        fichiers_hist, \n",
    "        size=min(nb_echantillons, len(fichiers_hist)), \n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    for fichier_hist in echantillons_fichiers:\n",
    "        try:\n",
    "            # Charger les données\n",
    "            donnees = np.load(fichier_hist, allow_pickle=True)\n",
    "            \n",
    "            # Vérifier la structure des données\n",
    "            if isinstance(donnees, np.ndarray) and donnees.dtype == object:\n",
    "                # Si c'est un tableau d'objets numpy, prendre le premier élément\n",
    "                hist_donnees = donnees.item() if donnees.size == 1 else donnees[()]\n",
    "            else:\n",
    "                hist_donnees = donnees.item() if donnees.ndim == 0 else donnees\n",
    "            \n",
    "            # Extraire l'histogramme et le label\n",
    "            if isinstance(hist_donnees, dict):\n",
    "                histogramme = hist_donnees['histogram']\n",
    "                label = hist_donnees['label']\n",
    "            else:\n",
    "                # Si ce n'est pas un dictionnaire, adapter selon votre structure\n",
    "                print(f\"Structure inattendue dans {os.path.basename(fichier_hist)}\")\n",
    "                print(f\"Type: {type(hist_donnees)}, Forme: {hist_donnees.shape if hasattr(hist_donnees, 'shape') else 'N/A'}\")\n",
    "                continue\n",
    "            \n",
    "            # Créer la visualisation\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.bar(range(len(histogramme)), histogramme, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            plt.title(f'Histogramme GHOST\\nFichier: {os.path.basename(fichier_hist)}\\nClasse: {label}', fontsize=14)\n",
    "            plt.xlabel('Bins', fontsize=12)\n",
    "            plt.ylabel('Fréquence', fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Afficher quelques informations statistiques\n",
    "            print(f\"\\nInformations pour {os.path.basename(fichier_hist)}:\")\n",
    "            print(f\"  - Classe: {label}\")\n",
    "            print(f\"  - Taille de l'histogramme: {len(histogramme)} bins\")\n",
    "            print(f\"  - Valeur maximale: {np.max(histogramme):.2f}\")\n",
    "            print(f\"  - Valeur moyenne: {np.mean(histogramme):.2f}\")\n",
    "            print(f\"  - Somme totale: {np.sum(histogramme):.2f}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement de {os.path.basename(fichier_hist)}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiser_histogrammes_echantillons(\"dataset_hist2\", nb_echantillons=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aeee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_sampling_notebook(cube, center_y, center_x, object_positions, \n",
    "                                background_positions, title=\"Échantillonnage\"):\n",
    "    \"\"\"\n",
    "    Visualise l'échantillonnage dans un notebook Jupyter.\n",
    "    \n",
    "    Args:\n",
    "        cube: Cube hyperspectral (H, W, Bands)\n",
    "        center_y, center_x: Coordonnées du centre\n",
    "        object_positions: Array de positions objet (N, 2)\n",
    "        background_positions: Array de positions fond (M, 2)\n",
    "        title: Titre du graphique\n",
    "    \"\"\"\n",
    "    h, w, bands = cube.shape\n",
    "    \n",
    "    # === 1. CRÉATION DE L'IMAGE RGB ===\n",
    "    if bands >= 3:\n",
    "        # Sélectionner 3 bandes pour créer une image RGB\n",
    "        # Bandes équi-réparties : début, milieu, fin\n",
    "        band_r = bands // 4          # ~25%\n",
    "        band_g = bands // 2          # ~50%\n",
    "        band_b = 3 * bands // 4      # ~75%\n",
    "        \n",
    "        rgb_image = cube[:, :, [band_r, band_g, band_b]]\n",
    "        print(f\"Bandes RGB sélectionnées: R={band_r}, G={band_g}, B={band_b}\")\n",
    "    else:\n",
    "        # Si moins de 3 bandes, grayscale répété\n",
    "        rgb_image = np.repeat(cube[:, :, 0:1], 3, axis=2)\n",
    "    \n",
    "    # Normalisation [0, 255]\n",
    "    rgb_min = rgb_image.min()\n",
    "    rgb_max = rgb_image.max()\n",
    "    rgb_image = ((rgb_image - rgb_min) / (rgb_max - rgb_min + 1e-8) * 255).astype(np.uint8)\n",
    "    \n",
    "    # === 2. CRÉATION DE LA FIGURE ===\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    # --- Subplot 1: Image originale ---\n",
    "    axes[0, 0].imshow(rgb_image)\n",
    "    axes[0, 0].set_title('Image Originale (Pseudo-RGB)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # --- Subplot 2: Pixels objet (verts) ---\n",
    "    overlay_object = rgb_image.copy()\n",
    "    for pos in object_positions[::5]:  # Sous-échantillonner pour visibilité\n",
    "        y, x = pos\n",
    "        cv2.circle(overlay_object, (x, y), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    # Marquer le centre en bleu\n",
    "    cv2.circle(overlay_object, (center_x, center_y), 8, (0, 0, 255), -1)\n",
    "    cv2.circle(overlay_object, (center_x, center_y), 10, (255, 255, 255), 2)\n",
    "    \n",
    "    axes[0, 1].imshow(overlay_object)\n",
    "    axes[0, 1].set_title(f'Pixels Objet (Vert, n={len(object_positions)})\\nCentre: ({center_y}, {center_x})', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # --- Subplot 3: Pixels fond (rouges) ---\n",
    "    overlay_background = rgb_image.copy()\n",
    "    for pos in background_positions[::5]:\n",
    "        y, x = pos\n",
    "        cv2.circle(overlay_background, (x, y), 2, (255, 0, 0), -1)\n",
    "    \n",
    "    axes[1, 0].imshow(overlay_background)\n",
    "    axes[1, 0].set_title(f'Pixels Fond Blanc (Rouge, n={len(background_positions)})', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # --- Subplot 4: Tout combiné ---\n",
    "    overlay_combined = rgb_image.copy()\n",
    "    \n",
    "    # Pixels fond en rouge\n",
    "    for pos in background_positions[::5]:\n",
    "        y, x = pos\n",
    "        cv2.circle(overlay_combined, (x, y), 2, (255, 0, 0), -1)\n",
    "    \n",
    "    # Pixels objet en vert (par-dessus)\n",
    "    for pos in object_positions[::5]:\n",
    "        y, x = pos\n",
    "        cv2.circle(overlay_combined, (x, y), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    # Centre en bleu\n",
    "    cv2.circle(overlay_combined, (center_x, center_y), 8, (0, 0, 255), -1)\n",
    "    cv2.circle(overlay_combined, (center_x, center_y), 10, (255, 255, 255), 2)\n",
    "    \n",
    "    # Blend avec l'image originale pour meilleure visibilité\n",
    "    overlay_combined = cv2.addWeighted(rgb_image, 0.6, overlay_combined, 0.4, 0)\n",
    "    \n",
    "    axes[1, 1].imshow(overlay_combined)\n",
    "    axes[1, 1].set_title('Combiné: Vert=Objet, Rouge=Fond, Bleu=Centre', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # === 3. STATISTIQUES ===\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"STATISTIQUES DE L'ÉCHANTILLONNAGE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Dimensions image: {h} × {w} × {bands} bandes\")\n",
    "    print(f\"Centre détecté: ({center_y}, {center_x})\")\n",
    "    print(f\"Pixels objet: {len(object_positions)}\")\n",
    "    print(f\"Pixels fond: {len(background_positions)}\")\n",
    "    print(f\"Total pixels: {len(object_positions) + len(background_positions)}\")\n",
    "    print(f\"Ratio Objet/Fond: {len(object_positions) / len(background_positions):.2f}:1\")\n",
    "\n",
    "\n",
    "def test_sampling_on_file(file_path, n_pixels_object=10000, n_pixels_background=5000):\n",
    "    \"\"\"\n",
    "    Teste l'échantillonnage sur un fichier et visualise le résultat.\n",
    "    \n",
    "    Usage dans notebook:\n",
    "        test_sampling_on_file('dataset_reflec/image_G1_sample1.npy')\n",
    "    \"\"\"\n",
    "    print(f\"Chargement: {file_path}\")\n",
    "    \n",
    "    # Charger le cube\n",
    "    cube = np.load(file_path)\n",
    "    \n",
    "    if cube.ndim != 3:\n",
    "        print(f\"❌ Erreur: le fichier doit être 3D, reçu shape={cube.shape}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Shape: {cube.shape}\")\n",
    "    \n",
    "    # 1. Trouver le centre\n",
    "    from cnn_1d import find_object_center, extract_pixels_around_center, detect_background_pixels\n",
    "    \n",
    "    print(\"\\n1️⃣ Détection du centre de l'objet...\")\n",
    "    center_y, center_x, object_mask = find_object_center(cube, method='variance')\n",
    "    print(f\"   Centre trouvé: ({center_y}, {center_x})\")\n",
    "    \n",
    "    # 2. Extraire pixels objet\n",
    "    print(f\"\\n2️⃣ Extraction de {n_pixels_object} pixels objet autour du centre...\")\n",
    "    object_pixels, object_positions = extract_pixels_around_center(\n",
    "        cube, center_y, center_x, n_pixels_object, method='circular'\n",
    "    )\n",
    "    print(f\"   Pixels extraits: {len(object_pixels)}\")\n",
    "    \n",
    "    # 3. Extraire pixels fond\n",
    "    print(f\"\\n3️⃣ Extraction de {n_pixels_background} pixels de fond blanc...\")\n",
    "    background_pixels, background_positions = detect_background_pixels(\n",
    "        cube, object_mask, n_pixels_background\n",
    "    )\n",
    "    print(f\"   Pixels extraits: {len(background_pixels)}\")\n",
    "    \n",
    "    # 4. Visualiser\n",
    "    print(f\"\\n4️⃣ Visualisation...\")\n",
    "    visualize_sampling_notebook(\n",
    "        cube, center_y, center_x, object_positions, background_positions,\n",
    "        title=f\"Échantillonnage - {os.path.basename(file_path)}\"\n",
    "    )\n",
    "    \n",
    "    # 5. Analyser les spectres\n",
    "    print(f\"\\n5️⃣ Analyse des spectres moyens...\")\n",
    "    analyze_spectra(object_pixels, background_pixels, cube.shape[2])\n",
    "    \n",
    "    return object_pixels, background_pixels, object_positions, background_positions\n",
    "\n",
    "\n",
    "def analyze_spectra(object_pixels, background_pixels, n_bands):\n",
    "    \"\"\"\n",
    "    Analyse et compare les spectres moyens objet vs fond.\n",
    "    \"\"\"\n",
    "    # Spectres moyens\n",
    "    mean_object = np.mean(object_pixels, axis=0)\n",
    "    mean_background = np.mean(background_pixels, axis=0)\n",
    "    \n",
    "    # Écarts-types\n",
    "    std_object = np.std(object_pixels, axis=0)\n",
    "    std_background = np.std(background_pixels, axis=0)\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    bands = np.arange(n_bands)\n",
    "    \n",
    "    # --- Spectres moyens ---\n",
    "    axes[0].plot(bands, mean_object, 'g-', linewidth=2, label='Objet (moyenne)')\n",
    "    axes[0].fill_between(bands, mean_object - std_object, mean_object + std_object, \n",
    "                         color='green', alpha=0.2, label='Objet (±1 std)')\n",
    "    \n",
    "    axes[0].plot(bands, mean_background, 'r-', linewidth=2, label='Fond (moyenne)')\n",
    "    axes[0].fill_between(bands, mean_background - std_background, mean_background + std_background,\n",
    "                         color='red', alpha=0.2, label='Fond (±1 std)')\n",
    "    \n",
    "    axes[0].set_xlabel('Bande spectrale', fontsize=12)\n",
    "    axes[0].set_ylabel('Intensité (réflectance)', fontsize=12)\n",
    "    axes[0].set_title('Spectres Moyens: Objet vs Fond', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- Différence ---\n",
    "    diff = mean_object - mean_background\n",
    "    \n",
    "    axes[1].plot(bands, diff, 'b-', linewidth=2)\n",
    "    axes[1].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[1].fill_between(bands, 0, diff, where=(diff > 0), color='green', alpha=0.3, label='Objet > Fond')\n",
    "    axes[1].fill_between(bands, 0, diff, where=(diff < 0), color='red', alpha=0.3, label='Fond > Objet')\n",
    "    \n",
    "    axes[1].set_xlabel('Bande spectrale', fontsize=12)\n",
    "    axes[1].set_ylabel('Différence (Objet - Fond)', fontsize=12)\n",
    "    axes[1].set_title('Différence Spectrale', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiques\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ANALYSE SPECTRALE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Intensité moyenne objet: {mean_object.mean():.4f} ± {mean_object.std():.4f}\")\n",
    "    print(f\"Intensité moyenne fond: {mean_background.mean():.4f} ± {mean_background.std():.4f}\")\n",
    "    print(f\"Différence moyenne: {diff.mean():.4f}\")\n",
    "    print(f\"Séparabilité (diff/std): {abs(diff.mean()) / (std_object.mean() + std_background.mean()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b384c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans votre Jupyter Notebook\n",
    "\n",
    "# 1. Importer les fonctions\n",
    "from cnn_1d import find_object_center, extract_pixels_around_center, detect_background_pixels\n",
    "\n",
    "# 2. Tester sur UN fichier\n",
    "test_sampling_on_file('dataset_reflec/2025-05-18-G2_20_class1.npy', \n",
    "                      n_pixels_object=10000, \n",
    "                      n_pixels_background=5000)\n",
    "\n",
    "# 3. Tester sur PLUSIEURS fichiers\n",
    "files = ['dataset_reflec/2025-04-03-G1_00-1_class0.npy',\n",
    "         'dataset_reflec/2025-05-18-G2_03_class1.npy',\n",
    "         'dataset_reflec/2025-05-06-G3_16_class2.npy',\n",
    "         'dataset_reflec/2025-05-18-G4_04_class3.npy']\n",
    "\n",
    "for file in files:\n",
    "    test_sampling_on_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def visualize_all_dataset_sampling(data_dir, n_pixels_object=10000, n_pixels_background=5000,\n",
    "                                   save_dir='visualizations', max_images=None):\n",
    "    \"\"\"\n",
    "    Visualise l'échantillonnage pour TOUTES les images du dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Répertoire contenant les fichiers .npy\n",
    "        n_pixels_object: Nombre de pixels objet par image\n",
    "        n_pixels_background: Nombre de pixels fond par image\n",
    "        save_dir: Répertoire pour sauvegarder les visualisations\n",
    "        max_images: Limite du nombre d'images (None = toutes)\n",
    "    \"\"\"\n",
    "    # Import des fonctions nécessaires\n",
    "    from cnn_1d import (find_object_center, extract_pixels_around_center, \n",
    "                        detect_background_pixels, extract_class_from_filename)\n",
    "    \n",
    "    # Créer le répertoire de sauvegarde\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Lister tous les fichiers .npy\n",
    "    files = sorted([f for f in os.listdir(data_dir) if f.endswith('.npy')])\n",
    "    \n",
    "    if max_images is not None:\n",
    "        files = files[:max_images]\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"VISUALISATION DE {len(files)} IMAGES\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Pixels objet/image: {n_pixels_object}\")\n",
    "    print(f\"Pixels fond/image: {n_pixels_background}\")\n",
    "    print(f\"Sauvegarde dans: {save_dir}/\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Statistiques globales\n",
    "    all_stats = []\n",
    "    \n",
    "    # Boucle sur tous les fichiers\n",
    "    for idx, filename in enumerate(tqdm(files, desc=\"Traitement des images\")):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Charger le cube\n",
    "            cube = np.load(file_path)\n",
    "            \n",
    "            if cube.ndim != 3:\n",
    "                print(f\"\\n⚠️  Ignoré (pas 3D): {filename}\")\n",
    "                continue\n",
    "            \n",
    "            h, w, bands = cube.shape\n",
    "            \n",
    "            # Extraire la classe\n",
    "            try:\n",
    "                class_label = extract_class_from_filename(file_path)\n",
    "            except:\n",
    "                class_label = \"Unknown\"\n",
    "            \n",
    "            # 1. Détecter le centre\n",
    "            center_y, center_x, object_mask = find_object_center(cube, method='variance')\n",
    "            \n",
    "            # 2. Extraire pixels objet\n",
    "            object_pixels, object_positions = extract_pixels_around_center(\n",
    "                cube, center_y, center_x, n_pixels_object, method='circular'\n",
    "            )\n",
    "            \n",
    "            # 3. Extraire pixels fond\n",
    "            background_pixels, background_positions = detect_background_pixels(\n",
    "                cube, object_mask, n_pixels_background\n",
    "            )\n",
    "            \n",
    "            # 4. Créer la visualisation\n",
    "            fig = create_single_image_visualization(\n",
    "                cube, center_y, center_x, object_positions, background_positions,\n",
    "                class_label, filename, h, w, bands\n",
    "            )\n",
    "            \n",
    "            # 5. Sauvegarder\n",
    "            save_path = os.path.join(save_dir, f\"{Path(filename).stem}_sampling.png\")\n",
    "            plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # 6. Collecter statistiques\n",
    "            stats = {\n",
    "                'filename': filename,\n",
    "                'class': class_label,\n",
    "                'shape': (h, w, bands),\n",
    "                'center': (center_y, center_x),\n",
    "                'n_object': len(object_pixels),\n",
    "                'n_background': len(background_pixels),\n",
    "                'mean_object': object_pixels.mean(),\n",
    "                'mean_background': background_pixels.mean(),\n",
    "                'std_object': object_pixels.std(),\n",
    "                'std_background': background_pixels.std()\n",
    "            }\n",
    "            all_stats.append(stats)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Erreur pour {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Résumé final\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RÉSUMÉ\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Images traitées: {len(all_stats)}/{len(files)}\")\n",
    "    print(f\"Visualisations sauvegardées dans: {save_dir}/\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Créer un résumé HTML\n",
    "    create_html_summary(all_stats, save_dir)\n",
    "    \n",
    "    return all_stats\n",
    "\n",
    "\n",
    "def create_single_image_visualization(cube, center_y, center_x, object_positions, \n",
    "                                      background_positions, class_label, filename,\n",
    "                                      h, w, bands):\n",
    "    \"\"\"\n",
    "    Crée une figure de visualisation pour UNE image.\n",
    "    \"\"\"\n",
    "    # Créer image RGB\n",
    "    if bands >= 3:\n",
    "        band_r = bands // 4\n",
    "        band_g = bands // 2\n",
    "        band_b = 3 * bands // 4\n",
    "        rgb_image = cube[:, :, [band_r, band_g, band_b]]\n",
    "    else:\n",
    "        rgb_image = np.repeat(cube[:, :, 0:1], 3, axis=2)\n",
    "    \n",
    "    # Normalisation\n",
    "    rgb_image = ((rgb_image - rgb_image.min()) / \n",
    "                 (rgb_image.max() - rgb_image.min() + 1e-8) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Créer figure avec 3 subplots\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # --- Subplot 1: Image originale ---\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    ax1.imshow(rgb_image)\n",
    "    ax1.set_title(f'Image Originale\\n{filename}\\nClasse: {class_label}', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # --- Subplot 2: Pixels objet (verts) ---\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    overlay_object = rgb_image.copy()\n",
    "    \n",
    "    # Dessiner tous les pixels objet (sous-échantillonné pour visibilité)\n",
    "    for pos in object_positions[::max(1, len(object_positions)//2000)]:\n",
    "        y, x = pos\n",
    "        cv2.circle(overlay_object, (x, y), 1, (0, 255, 0), -1)\n",
    "    \n",
    "    # Marquer le centre\n",
    "    cv2.circle(overlay_object, (center_x, center_y), 6, (0, 0, 255), -1)\n",
    "    cv2.circle(overlay_object, (center_x, center_y), 8, (255, 255, 255), 2)\n",
    "    \n",
    "    # Tracer le cercle de sélection\n",
    "    radius = int(np.sqrt(len(object_positions) / np.pi))\n",
    "    cv2.circle(overlay_object, (center_x, center_y), radius, (255, 255, 0), 2)\n",
    "    \n",
    "    ax2.imshow(overlay_object)\n",
    "    ax2.set_title(f'Pixels Objet (n={len(object_positions)})\\nCentre: ({center_y}, {center_x})\\nRadius: {radius}', \n",
    "                  fontsize=12, fontweight='bold', color='green')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # --- Subplot 3: Pixels fond (rouges) ---\n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "    overlay_background = rgb_image.copy()\n",
    "    \n",
    "    # Dessiner tous les pixels fond\n",
    "    for pos in background_positions[::max(1, len(background_positions)//2000)]:\n",
    "        y, x = pos\n",
    "        cv2.circle(overlay_background, (x, y), 1, (255, 0, 0), -1)\n",
    "    \n",
    "    # Marquer les zones de bords préférées\n",
    "    border_size = max(h, w) // 10\n",
    "    cv2.rectangle(overlay_background, (0, 0), (border_size, h), (255, 255, 0), 2)\n",
    "    cv2.rectangle(overlay_background, (w-border_size, 0), (w, h), (255, 255, 0), 2)\n",
    "    cv2.rectangle(overlay_background, (0, 0), (w, border_size), (255, 255, 0), 2)\n",
    "    cv2.rectangle(overlay_background, (0, h-border_size), (w, h), (255, 255, 0), 2)\n",
    "    \n",
    "    ax3.imshow(overlay_background)\n",
    "    ax3.set_title(f'Pixels Fond (n={len(background_positions)})\\nZones préférées: bords/coins', \n",
    "                  fontsize=12, fontweight='bold', color='red')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{filename} - Classe {class_label} - Shape: {h}×{w}×{bands}', \n",
    "                 fontsize=14, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_html_summary(all_stats, save_dir):\n",
    "    \"\"\"\n",
    "    Crée un fichier HTML pour visualiser toutes les images facilement.\n",
    "    \"\"\"\n",
    "    html_path = os.path.join(save_dir, 'index.html')\n",
    "    \n",
    "    # Calculer statistiques globales\n",
    "    n_images = len(all_stats)\n",
    "    classes = sorted(list(set([s['class'] for s in all_stats])))\n",
    "    total_object = sum([s['n_object'] for s in all_stats])\n",
    "    total_background = sum([s['n_background'] for s in all_stats])\n",
    "    \n",
    "    # Créer les lignes du tableau\n",
    "    table_rows = []\n",
    "    for s in all_stats:\n",
    "        row = f\"\"\"\n",
    "            <tr>\n",
    "                <td>{s['filename']}</td>\n",
    "                <td>{s['class']}</td>\n",
    "                <td>{s['shape'][0]}×{s['shape'][1]}×{s['shape'][2]}</td>\n",
    "                <td>({s['center'][0]}, {s['center'][1]})</td>\n",
    "                <td>{s['n_object']}</td>\n",
    "                <td>{s['n_background']}</td>\n",
    "                <td>{s['mean_object']:.4f}</td>\n",
    "                <td>{s['mean_background']:.4f}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "        table_rows.append(row)\n",
    "    \n",
    "    # Créer les cartes d'images\n",
    "    image_cards = []\n",
    "    for s in all_stats:\n",
    "        img_filename = f\"{Path(s['filename']).stem}_sampling.png\"\n",
    "        card = f\"\"\"\n",
    "        <div class=\"image-card\">\n",
    "            <img src=\"{img_filename}\" alt=\"{s['filename']}\">\n",
    "            <div class=\"image-info\">\n",
    "                <strong>{s['filename']}</strong><br>\n",
    "                Classe: {s['class']} | Shape: {s['shape'][0]}×{s['shape'][1]}×{s['shape'][2]}<br>\n",
    "                Centre: ({s['center'][0]}, {s['center'][1]}) | \n",
    "                Objet: {s['n_object']} | Fond: {s['n_background']}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        image_cards.append(card)\n",
    "    \n",
    "    # Template HTML (sans .format(), utilisation de f-string directement)\n",
    "    html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Dataset Sampling Visualization</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }}\n",
    "        h1 {{\n",
    "            color: #333;\n",
    "            text-align: center;\n",
    "        }}\n",
    "        .stats {{\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            margin: 20px 0;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .image-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(600px, 1fr));\n",
    "            gap: 20px;\n",
    "            margin-top: 20px;\n",
    "        }}\n",
    "        .image-card {{\n",
    "            background: white;\n",
    "            padding: 15px;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .image-card img {{\n",
    "            width: 100%;\n",
    "            height: auto;\n",
    "            border-radius: 4px;\n",
    "        }}\n",
    "        .image-info {{\n",
    "            margin-top: 10px;\n",
    "            font-size: 14px;\n",
    "            color: #666;\n",
    "        }}\n",
    "        .image-info strong {{\n",
    "            color: #333;\n",
    "        }}\n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin-top: 10px;\n",
    "        }}\n",
    "        th, td {{\n",
    "            padding: 8px;\n",
    "            text-align: left;\n",
    "            border-bottom: 1px solid #ddd;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #4CAF50;\n",
    "            color: white;\n",
    "        }}\n",
    "        tr:hover {{\n",
    "            background-color: #f5f5f5;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>🔬 Dataset Sampling Visualization</h1>\n",
    "    \n",
    "    <div class=\"stats\">\n",
    "        <h2>📊 Statistiques Globales</h2>\n",
    "        <p><strong>Nombre d'images:</strong> {n_images}</p>\n",
    "        <p><strong>Classes présentes:</strong> {', '.join(map(str, classes))}</p>\n",
    "        <p><strong>Total pixels objet:</strong> {total_object:,}</p>\n",
    "        <p><strong>Total pixels fond:</strong> {total_background:,}</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"stats\">\n",
    "        <h2>📋 Détails par Image</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Fichier</th>\n",
    "                <th>Classe</th>\n",
    "                <th>Shape (H×W×B)</th>\n",
    "                <th>Centre (Y, X)</th>\n",
    "                <th>Pixels Objet</th>\n",
    "                <th>Pixels Fond</th>\n",
    "                <th>Mean Objet</th>\n",
    "                <th>Mean Fond</th>\n",
    "            </tr>\n",
    "            {''.join(table_rows)}\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "    <h2>🖼️ Visualisations</h2>\n",
    "    <div class=\"image-grid\">\n",
    "        {''.join(image_cards)}\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    \n",
    "    # Sauvegarder\n",
    "    with open(html_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"\\n✅ Résumé HTML créé: {html_path}\")\n",
    "    print(f\"   Ouvrez ce fichier dans votre navigateur pour voir toutes les visualisations\")\n",
    "\n",
    "def visualize_dataset_summary(all_stats):\n",
    "    \"\"\"\n",
    "    Créer une vue d'ensemble des statistiques du dataset.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Convertir en DataFrame\n",
    "    df = pd.DataFrame(all_stats)\n",
    "    \n",
    "    # Afficher statistiques par classe\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"STATISTIQUES PAR CLASSE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for class_label in sorted(df['class'].unique()):\n",
    "        class_df = df[df['class'] == class_label]\n",
    "        print(f\"\\nClasse {class_label}:\")\n",
    "        print(f\"  Nombre d'images: {len(class_df)}\")\n",
    "        print(f\"  Mean objet (avg): {class_df['mean_object'].mean():.4f} ± {class_df['mean_object'].std():.4f}\")\n",
    "        print(f\"  Mean fond (avg): {class_df['mean_background'].mean():.4f} ± {class_df['mean_background'].std():.4f}\")\n",
    "    \n",
    "    # Visualisation des distributions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Distribution des intensités objet vs fond\n",
    "    axes[0, 0].hist(df['mean_object'], bins=30, alpha=0.6, label='Objet', color='green')\n",
    "    axes[0, 0].hist(df['mean_background'], bins=30, alpha=0.6, label='Fond', color='red')\n",
    "    axes[0, 0].set_xlabel('Intensité moyenne')\n",
    "    axes[0, 0].set_ylabel('Fréquence')\n",
    "    axes[0, 0].set_title('Distribution des intensités moyennes')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Position des centres par classe\n",
    "    for class_label in sorted(df['class'].unique()):\n",
    "        class_df = df[df['class'] == class_label]\n",
    "        centers_y = [c[0] for c in class_df['center']]\n",
    "        centers_x = [c[1] for c in class_df['center']]\n",
    "        axes[0, 1].scatter(centers_x, centers_y, label=f'Classe {class_label}', alpha=0.6, s=50)\n",
    "    axes[0, 1].set_xlabel('X')\n",
    "    axes[0, 1].set_ylabel('Y')\n",
    "    axes[0, 1].set_title('Position des centres détectés')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].invert_yaxis()  # Y augmente vers le bas dans les images\n",
    "    \n",
    "    # Boxplot des intensités par classe\n",
    "    data_object = [df[df['class'] == c]['mean_object'].values for c in sorted(df['class'].unique())]\n",
    "    data_background = [df[df['class'] == c]['mean_background'].values for c in sorted(df['class'].unique())]\n",
    "    \n",
    "    positions_obj = np.arange(len(data_object)) * 2\n",
    "    positions_bg = np.arange(len(data_background)) * 2 + 0.6\n",
    "    \n",
    "    bp1 = axes[1, 0].boxplot(data_object, positions=positions_obj, widths=0.5, \n",
    "                             patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n",
    "    bp2 = axes[1, 0].boxplot(data_background, positions=positions_bg, widths=0.5,\n",
    "                             patch_artist=True, boxprops=dict(facecolor='lightcoral'))\n",
    "    \n",
    "    axes[1, 0].set_xticks(positions_obj + 0.3)\n",
    "    axes[1, 0].set_xticklabels([f'Classe {c}' for c in sorted(df['class'].unique())])\n",
    "    axes[1, 0].set_ylabel('Intensité moyenne')\n",
    "    axes[1, 0].set_title('Intensités par classe')\n",
    "    axes[1, 0].legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0]], ['Objet', 'Fond'])\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Séparabilité objet/fond par image\n",
    "    separability = (df['mean_object'] - df['mean_background']).abs()\n",
    "    axes[1, 1].hist(separability, bins=30, color='purple', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('|Mean Objet - Mean Fond|')\n",
    "    axes[1, 1].set_ylabel('Fréquence')\n",
    "    axes[1, 1].set_title('Séparabilité Objet/Fond')\n",
    "    axes[1, 1].axvline(separability.mean(), color='red', linestyle='--', \n",
    "                      label=f'Moyenne: {separability.mean():.4f}')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('visualizations', 'dataset_summary.png'), dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✅ Graphique résumé sauvegardé: visualizations/dataset_summary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49336a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Visualiser TOUT le dataset\n",
    "stats = visualize_all_dataset_sampling(\n",
    "    data_dir='dataset_reflec',\n",
    "    n_pixels_object=10000,\n",
    "    n_pixels_background=5000,\n",
    "    save_dir='visualizations',\n",
    "    max_images=None  # None = toutes les images\n",
    ")\n",
    "\n",
    "# 2. Voir le résumé statistique\n",
    "visualize_dataset_summary(stats)\n",
    "\n",
    "# 3. Ouvrir le fichier HTML dans votre navigateur\n",
    "# → visualizations/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39974f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser seulement les 10 premières images\n",
    "stats = visualize_all_dataset_sampling(\n",
    "    data_dir='dataset_reflec',\n",
    "    max_images=10,\n",
    "    save_dir='visualizations_test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac90a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def visualize_ghost_histograms(npy_file):\n",
    "    \"\"\"\n",
    "    Visualise les histogrammes GHOST d'un fichier .npy.\n",
    "    \n",
    "    Args:\n",
    "        npy_file: Chemin vers le fichier .npy contenant les histogrammes\n",
    "    \"\"\"\n",
    "    # Charger les données\n",
    "    data = np.load(npy_file)\n",
    "    \n",
    "    print(f\"Fichier: {os.path.basename(npy_file)}\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    print(f\"Type: {data.dtype}\")\n",
    "    print(f\"Min: {data.min():.6f}, Max: {data.max():.6f}\")\n",
    "    print(f\"Mean: {data.mean():.6f}, Std: {data.std():.6f}\")\n",
    "    \n",
    "    # Détecter le format\n",
    "    if data.ndim == 3 and data.shape[0] == 1 and data.shape[1] == 1:\n",
    "        # Format (1, 1, features) - aplatir en 1D\n",
    "        data_1d = data.squeeze()\n",
    "        print(f\"\\nFormat détecté: (1, 1, {len(data_1d)}) → Vecteur 1D\")\n",
    "        visualize_as_1d(data_1d, npy_file)\n",
    "        \n",
    "    elif data.ndim == 2:\n",
    "        # Format (4, num_bins) ou (num_bins, 4)\n",
    "        print(f\"\\nFormat détecté: Matrice 2D ({data.shape[0]} × {data.shape[1]})\")\n",
    "        \n",
    "        # Détecter orientation\n",
    "        if data.shape[0] == 4:\n",
    "            # (4, num_bins) - histogrammes en lignes\n",
    "            print(\"Orientation: 4 histogrammes en LIGNES\")\n",
    "            visualize_as_2d_rows(data, npy_file)\n",
    "        elif data.shape[1] == 4:\n",
    "            # (num_bins, 4) - histogrammes en colonnes\n",
    "            print(\"Orientation: 4 histogrammes en COLONNES\")\n",
    "            visualize_as_2d_cols(data, npy_file)\n",
    "        else:\n",
    "            # Format inconnu, essayer les deux visualisations\n",
    "            print(\"Orientation: Inconnue, affichage des deux possibilités\")\n",
    "            visualize_as_2d_both(data, npy_file)\n",
    "    \n",
    "    elif data.ndim == 1:\n",
    "        # Vecteur 1D\n",
    "        print(f\"\\nFormat détecté: Vecteur 1D ({len(data)} valeurs)\")\n",
    "        visualize_as_1d(data, npy_file)\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\n⚠️  Format non reconnu: {data.shape}\")\n",
    "\n",
    "\n",
    "def visualize_as_1d(data, npy_file):\n",
    "    \"\"\"\n",
    "    Visualise un vecteur 1D (histogrammes concaténés).\n",
    "    \"\"\"\n",
    "    n_features = len(data)\n",
    "    \n",
    "    # Deviner le nombre de bins par histogramme\n",
    "    # Si n_features est divisible par 4, on a probablement 4 histogrammes\n",
    "    if n_features % 4 == 0:\n",
    "        num_bins = n_features // 4\n",
    "        print(f\"Déduction: 4 histogrammes × {num_bins} bins = {n_features} features\")\n",
    "        \n",
    "        # Reshape en (4, num_bins)\n",
    "        data_2d = data.reshape(4, num_bins)\n",
    "        \n",
    "        # Visualiser comme matrice 2D\n",
    "        visualize_as_2d_rows(data_2d, npy_file)\n",
    "    else:\n",
    "        # Visualisation brute du vecteur\n",
    "        fig, ax = plt.subplots(figsize=(16, 4))\n",
    "        ax.plot(data, linewidth=1)\n",
    "        ax.set_xlabel('Index', fontsize=12)\n",
    "        ax.set_ylabel('Valeur', fontsize=12)\n",
    "        ax.set_title(f'Vecteur 1D - {os.path.basename(npy_file)}\\n{n_features} valeurs', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def visualize_as_2d_rows(data, npy_file):\n",
    "    \"\"\"\n",
    "    Visualise une matrice 2D avec histogrammes en LIGNES (4, num_bins).\n",
    "    \"\"\"\n",
    "    n_hists, num_bins = data.shape\n",
    "    \n",
    "    hist_names = ['Magnitude (T)', 'Direction (θ)', 'Distance G', 'Distance W']\n",
    "    \n",
    "    if n_hists != 4:\n",
    "        hist_names = [f'Histogramme {i+1}' for i in range(n_hists)]\n",
    "    \n",
    "    # Créer figure avec 3 types de visualisations\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # === 1. Courbes séparées (4 subplots) ===\n",
    "    for i in range(n_hists):\n",
    "        ax = plt.subplot(4, 3, i*3 + 1)\n",
    "        ax.plot(data[i], linewidth=2, color=f'C{i}')\n",
    "        ax.fill_between(range(num_bins), data[i], alpha=0.3, color=f'C{i}')\n",
    "        ax.set_ylabel('Densité', fontsize=10)\n",
    "        ax.set_title(hist_names[i] if i < len(hist_names) else f'Hist {i+1}', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if i == n_hists - 1:\n",
    "            ax.set_xlabel('Bin', fontsize=10)\n",
    "    \n",
    "    # === 2. Superposition ===\n",
    "    ax_overlay = plt.subplot(1, 3, 2)\n",
    "    for i in range(n_hists):\n",
    "        ax_overlay.plot(data[i], linewidth=2, label=hist_names[i] if i < len(hist_names) else f'Hist {i+1}')\n",
    "    ax_overlay.set_xlabel('Bin', fontsize=12)\n",
    "    ax_overlay.set_ylabel('Densité', fontsize=12)\n",
    "    ax_overlay.set_title('Superposition des 4 histogrammes', fontsize=14, fontweight='bold')\n",
    "    ax_overlay.legend(fontsize=10)\n",
    "    ax_overlay.grid(True, alpha=0.3)\n",
    "    \n",
    "    # === 3. Heatmap ===\n",
    "    ax_heatmap = plt.subplot(1, 3, 3)\n",
    "    im = ax_heatmap.imshow(data, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "    ax_heatmap.set_xlabel('Bin', fontsize=12)\n",
    "    ax_heatmap.set_ylabel('Histogramme', fontsize=12)\n",
    "    ax_heatmap.set_title('Heatmap (Intensité = Densité)', fontsize=14, fontweight='bold')\n",
    "    ax_heatmap.set_yticks(range(n_hists))\n",
    "    ax_heatmap.set_yticklabels([hist_names[i] if i < len(hist_names) else f'H{i+1}' for i in range(n_hists)])\n",
    "    plt.colorbar(im, ax=ax_heatmap, label='Densité')\n",
    "    \n",
    "    plt.suptitle(f'Visualisation GHOST - {os.path.basename(npy_file)}\\nFormat: ({n_hists} histogrammes, {num_bins} bins chacun)', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # === 4. Statistiques ===\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"STATISTIQUES PAR HISTOGRAMME\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for i in range(n_hists):\n",
    "        name = hist_names[i] if i < len(hist_names) else f'Histogramme {i+1}'\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Min:  {data[i].min():.6f}\")\n",
    "        print(f\"  Max:  {data[i].max():.6f}\")\n",
    "        print(f\"  Mean: {data[i].mean():.6f}\")\n",
    "        print(f\"  Std:  {data[i].std():.6f}\")\n",
    "        print(f\"  Sum:  {data[i].sum():.6f} (devrait ≈ 1.0 si normalisé)\")\n",
    "\n",
    "\n",
    "def visualize_as_2d_cols(data, npy_file):\n",
    "    \"\"\"\n",
    "    Visualise une matrice 2D avec histogrammes en COLONNES (num_bins, 4).\n",
    "    \"\"\"\n",
    "    # Transposer pour avoir histogrammes en lignes\n",
    "    data_transposed = data.T\n",
    "    visualize_as_2d_rows(data_transposed, npy_file)\n",
    "\n",
    "\n",
    "def visualize_as_2d_both(data, npy_file):\n",
    "    \"\"\"\n",
    "    Visualise les deux interprétations possibles (lignes et colonnes).\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Interprétation 1: Histogrammes en LIGNES ===\")\n",
    "    visualize_as_2d_rows(data, npy_file)\n",
    "    \n",
    "    print(\"\\n=== Interprétation 2: Histogrammes en COLONNES ===\")\n",
    "    visualize_as_2d_cols(data, npy_file)\n",
    "\n",
    "\n",
    "def compare_multiple_files(npy_files, max_files=5):\n",
    "    \"\"\"\n",
    "    Compare plusieurs fichiers GHOST côte à côte.\n",
    "    \n",
    "    Args:\n",
    "        npy_files: Liste de chemins vers fichiers .npy\n",
    "        max_files: Nombre maximum de fichiers à comparer\n",
    "    \"\"\"\n",
    "    npy_files = npy_files[:max_files]\n",
    "    \n",
    "    n_files = len(npy_files)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_files, 2, figsize=(16, 4*n_files))\n",
    "    \n",
    "    if n_files == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, npy_file in enumerate(npy_files):\n",
    "        data = np.load(npy_file)\n",
    "        \n",
    "        # Détecter format et normaliser en (4, num_bins)\n",
    "        if data.ndim == 3 and data.shape[0] == 1 and data.shape[1] == 1:\n",
    "            data_1d = data.squeeze()\n",
    "            if len(data_1d) % 4 == 0:\n",
    "                num_bins = len(data_1d) // 4\n",
    "                data_2d = data_1d.reshape(4, num_bins)\n",
    "            else:\n",
    "                continue\n",
    "        elif data.ndim == 2:\n",
    "            if data.shape[0] == 4:\n",
    "                data_2d = data\n",
    "            elif data.shape[1] == 4:\n",
    "                data_2d = data.T\n",
    "            else:\n",
    "                continue\n",
    "        elif data.ndim == 1 and len(data) % 4 == 0:\n",
    "            num_bins = len(data) // 4\n",
    "            data_2d = data.reshape(4, num_bins)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Extraire info du nom de fichier\n",
    "        basename = os.path.basename(npy_file)\n",
    "        try:\n",
    "            class_label = basename.split('class')[1].split('.')[0]\n",
    "        except:\n",
    "            class_label = \"?\"\n",
    "        \n",
    "        # Subplot 1: Superposition\n",
    "        hist_names = ['T', 'θ', 'G', 'W']\n",
    "        for i in range(4):\n",
    "            axes[idx, 0].plot(data_2d[i], linewidth=2, label=hist_names[i], alpha=0.8)\n",
    "        axes[idx, 0].set_title(f'{basename}\\nClasse: {class_label}', fontsize=11, fontweight='bold')\n",
    "        axes[idx, 0].set_ylabel('Densité', fontsize=10)\n",
    "        axes[idx, 0].legend(fontsize=9)\n",
    "        axes[idx, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Subplot 2: Heatmap\n",
    "        im = axes[idx, 1].imshow(data_2d, aspect='auto', cmap='viridis')\n",
    "        axes[idx, 1].set_title(f'Heatmap - Classe {class_label}', fontsize=11, fontweight='bold')\n",
    "        axes[idx, 1].set_ylabel('Histogramme', fontsize=10)\n",
    "        axes[idx, 1].set_yticks(range(4))\n",
    "        axes[idx, 1].set_yticklabels(hist_names)\n",
    "        plt.colorbar(im, ax=axes[idx, 1])\n",
    "    \n",
    "    plt.suptitle('Comparaison de fichiers GHOST', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def explore_ghost_dataset(dataset_dir, max_display=5):\n",
    "    \"\"\"\n",
    "    Explore un répertoire entier de fichiers GHOST.\n",
    "    \n",
    "    Args:\n",
    "        dataset_dir: Répertoire contenant les .npy\n",
    "        max_display: Nombre max de fichiers à afficher en détail\n",
    "    \"\"\"\n",
    "    # Lister tous les fichiers\n",
    "    npy_files = sorted([os.path.join(dataset_dir, f) \n",
    "                       for f in os.listdir(dataset_dir) \n",
    "                       if f.endswith('.npy')])\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"EXPLORATION DU DATASET GHOST\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Répertoire: {dataset_dir}\")\n",
    "    print(f\"Fichiers trouvés: {len(npy_files)}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Analyser tous les fichiers\n",
    "    shapes = []\n",
    "    for npy_file in npy_files:\n",
    "        data = np.load(npy_file)\n",
    "        shapes.append(data.shape)\n",
    "    \n",
    "    # Résumé des shapes\n",
    "    unique_shapes = list(set(shapes))\n",
    "    print(\"Shapes trouvées:\")\n",
    "    for shape in unique_shapes:\n",
    "        count = shapes.count(shape)\n",
    "        print(f\"  {shape}: {count} fichiers ({100*count/len(shapes):.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"VISUALISATION DÉTAILLÉE ({max_display} premiers fichiers)\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Visualiser quelques fichiers en détail\n",
    "    for npy_file in npy_files[:max_display]:\n",
    "        visualize_ghost_histograms(npy_file)\n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Comparaison côte à côte\n",
    "    if len(npy_files) >= 2:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"COMPARAISON CÔTE À CÔTE\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        compare_multiple_files(npy_files, max_files=min(5, len(npy_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ghost_histograms('dataset_hist/2025-04-03-G1_00-1_hist_class0.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba80b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utiliser matplotlib  pourafficher les valeur de la matrice 2D des histogrammes \n",
    "matrice = np.load('dataset_hist/2025-04-03-G1_00-1_hist_class0.npy')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "im = ax.imshow(matrice, cmap='YlGn') # Jaune à Vert\n",
    "\n",
    "# Afficher les valeurs numériques dans chaque case\n",
    "for i in range(len(matrice)):\n",
    "    for j in range(len(matrice[0])):\n",
    "        text = ax.text(j, i, round(matrice[i, j], 2),\n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "plt.title(\"Visualisation d'une matrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice = np.load('dataset_hist/2025-05-18-G4_20_hist_class3.npy')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "im = ax.imshow(matrice, cmap='YlGn') # Jaune à Vert\n",
    "\n",
    "# Afficher les valeurs numériques dans chaque case\n",
    "for i in range(len(matrice)):\n",
    "    for j in range(len(matrice[0])):\n",
    "        text = ax.text(j, i, round(matrice[i, j], 2),\n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "plt.title(\"Visualisation d'une matrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice = np.load('dataset_hist/2025-05-06-G3_19_hist_class2.npy')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "im = ax.imshow(matrice, cmap='YlGn') # Jaune à Vert\n",
    "\n",
    "# Afficher les valeurs numériques dans chaque case\n",
    "for i in range(len(matrice)):\n",
    "    for j in range(len(matrice[0])):\n",
    "        text = ax.text(j, i, round(matrice[i, j], 2),\n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "plt.title(\"Visualisation d'une matrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d933903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
