# Projet ImViA ‚Äî Classification d'Images Hyperspectrales

## üìã Description

Ce d√©p√¥t contient des scripts pour l'extraction, l'entra√Ænement et l'√©valuation de mod√®les de classification sur images hyperspectrales. Les approches disponibles incluent :
- CNN 1D (spectral) ‚Äî traitement pixel par pixel le long des bandes
- CNN 2D (patchs) ‚Äî convolutions spatiales sur patches multispectraux
- CNN 3D (cubes) ‚Äî convolutions spatiales+spectrales

Le workflow typique : extraire des pixels/cubes autour des centres d'objets, entra√Æner un mod√®le, puis √©valuer sur un jeu de test.

---

## üìÅ Fichiers et scripts importants

- `data_processor.py` : traitements d'utilit√© (extraction, normalisation)
- `loader.py` : utilitaires de chargement et cr√©ation des datasets
- `cnn_1d.py` : entra√Ænement et test du CNN 1D (spectral) ‚Äî principal script utilis√©
- `cnn_2d.py` : entra√Ænement CNN 2D (patches)
- `cnn_3d.py` : entra√Ænement CNN 3D (cubes)
- `transfer.py` : entra√Ænement par transfert (patch-based, fine-tuning de backbones pr√©-entra√Æn√©s)
- `test_cnn1d.py` / `test_spectral.ipynb` : √©valuation et analyses
- `train.ipynb`, `hyper_classifier.ipynb` : notebooks d'exp√©rimentation
- `dataset_reflec/`, `dataset_reflec_test/`, `dataset_hist/`, `dataset_hist2/` : exemples de dossiers de donn√©es
- `hyperspectral_dataset_summary.csv` : fichier de m√©tadonn√©es (centres, classes)

---

## üöÄ Installation rapide

Pr√©requis : Python 3.8+, PyTorch (MPS ou CUDA si disponible).

Installation minimale :

```bash
pip install -r requirements.txt
# ou
pip install numpy pandas torch torchvision scikit-learn matplotlib seaborn opencv-python
```

Pour Apple Silicon, installez la roue PyTorch compatible MPS ; pour NVIDIA, installez la roue CUDA adapt√©e.

---

## üîß Exemples d'utilisation

### 1) Entra√Æner le CNN 1D (spectral)

```bash
python cnn_1d.py \
  --data_dir dataset_hist2 \
  --csv_path hyperspectral_dataset_summary.csv \
  --n_pixels_object 10000 \
  --max_files 109 \
  --architecture medium \
  --batch_size 128 \
  --epochs 60 \
  --learning_rate 0.001
```

Param√®tres principaux : `--data_dir`, `--csv_path`, `--n_pixels_object`, `--architecture` (`simple|medium|deep`), `--batch_size`, `--epochs`.

### 2) Entra√Æner le CNN 2D (patches)

```bash
python cnn_2d.py \
  --data_dir dataset_reflec \
  --csv_path hyperspectral_dataset_summary.csv \
  --patch_size 32 \
  --architecture medium \
  --batch_size 64 \
  --epochs 100
```

### 3) Entra√Æner le CNN 3D (cubes)

```bash
python cnn_3d.py \
  --data_dir dataset_reflec \
  --csv_path hyperspectral_dataset_summary.csv \
  --patch_size 11 \
  --stride 2 \
  --architecture deep \
  --batch_size 16 \
  --epochs 100
```

### 4) Entra√Ænement par transfert ‚Äî `transfer.py`

**Objectif** : Fine-tuning d'un backbone pr√©-entra√Æn√© (ResNet / MobileNet / DenseNet) sur des patches extraits des `.npy`. Le jeu de donn√©es est index√© de fa√ßon paresseuse (lazy), utile pour traiter de grands volumes sans tout charger en m√©moire.

**Options principales** :
- `--data_dir` : r√©pertoire contenant les `.npy`
- `--data_type` : `reflec` (cubes H√óW√óB) ou `ghost` (histogrammes 1D)
- `--patch_size` : taille des patches extraits (ex: 11, 32)
- `--stride` : pas d'extraction des patches
- `--max_patches_per_file` : nombre max de patches par fichier
- `--max_samples` : nombre total maximal d'√©chantillons index√©s
- `--arch` : `resnet50` | `mobilenet_v2` | `densenet121` (backbones pr√©-entra√Æn√©s)
- `--batch_size`, `--epochs`, `--lr`
- `--save_model` (par d√©faut `best_transfer.pt`), `--save_history`

**Particularit√©s** :
- Le backbone est gel√© (les poids ne sont pas entra√Æn√©s) et seule la t√™te (classifier) est entra√Æn√©e par d√©faut.
- Le dataset est construit de fa√ßon paresseuse : seuls les patches n√©cessaires sont lus au runtime.
- Le script d√©tecte automatiquement MPS / CUDA / CPU.

**Exemple d'ex√©cution (commande typique)** :
```bash
python transfer.py \
  --data_dir dataset_reflec \
  --data_type reflec \
  --arch densenet121 \
  --max_samples 100000 \
  --max_patches_per_file 100 \
  --stride 5 \
  --batch_size 64 \
  --epochs 50
```

**Sorties** :
- `best_transfer.pt` : checkpoint du meilleur mod√®le (etat du classifier et m√©tadonn√©es)
- `history_transfer.png` : courbes d'entra√Ænement (loss / accuracy)

### 5) √âvaluer un mod√®le pr√©-entra√Æn√©

```bash
python test_cnn1d.py \
  --test_data_dir dataset_reflec_test \
  --csv_path hyperspectral_dataset_summary.csv \
  --model_path best_cnn1d_csv.pth \
  --n_pixels_object 10000 \
  --batch_size 128
```

---

## ‚ö†Ô∏è Notes importantes et d√©pannage

- Validation de la taille spectrale (nouvelle s√©curit√©) :
  - Le script `cnn_1d.py` v√©rifie d√©sormais que le nombre de bandes (`input_channels`) est suffisant pour l'architecture choisie (ex. `medium`/`deep` effectuent 3 poolings ‚Üí n√©cessit√© d'au moins 8 bandes). Si `input_channels` est trop petit, une **ValueError** explicite sera lev√©e avec un message d'aide.
  - Solution : utiliser `--architecture simple` ou fournir des fichiers `.npy` avec plus de bandes.

- Erreur li√©e √† `MaxPool1d` (s√©quence trop courte) : signifie g√©n√©ralement que la longueur spectrale a √©t√© r√©duite √† 0 apr√®s pooling ‚Äî voir point pr√©c√©dent.

- GPU OOM : r√©duire `--batch_size` (ex. 128 ‚Üí 64 ou 16 pour CNN 3D).

- CSV manquant : v√©rifiez que `hyperspectral_dataset_summary.csv` contient les colonnes requises (`Nom_Fichier_npy` / `Filename`, `Yc`, `Xc`, `Classe` selon le script utilis√©).

---

## üìÑ Format des donn√©es

- `.npy` : cubes 3D `(Height, Width, Bands)`
- CSV de centres : contient au minimum les colonnes indiquant le nom du fichier et les coordonn√©es du centre (Xc/Yc) et la classe.

---

## üßæ Remarques finales

- Les notebooks (`train.ipynb`, `hyper_classifier.ipynb`) contiennent des exp√©riences et visualisations compl√©mentaires.
- Pour toute question ou probl√®me reproductible, ouvrez une issue en pr√©cisant la commande ex√©cut√©e et l'erreur compl√®te.

---

*README mis √† jour pour refl√©ter les scripts et comportements actuels du d√©p√¥t.*

Si vous utilisez ce code dans vos recherches, veuillez citer :

```
Projet de Classification d'Images Hyperspectrales
Deep Learning pour analyse spectrale
2025
```

---

## üë• Auteurs

- Boris DJOUM

---

## üìÑ Licence

Ce projet est sous licence MIT. Libre d'utilisation pour la recherche et l'√©ducation.

---

## üîó Ressources Compl√©mentaires

- [PyTorch Documentation](https://pytorch.org/docs/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Introduction √† l'imagerie hyperspectrale](https://en.wikipedia.org/wiki/Hyperspectral_imaging)

---

**Bonne classification ! üöÄ**